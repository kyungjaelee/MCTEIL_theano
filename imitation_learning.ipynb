{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mMKL runtime not found. Will not attempt to disable multithreaded MKL for parallel rollouts.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import argparse, h5py, json\n",
    "import numpy as np\n",
    "from environments import rlgymenv\n",
    "import policyopt\n",
    "import yaml\n",
    "import os\n",
    "from policyopt import imitation, nn, rl, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MODES = ('bclone', 'ga')\n",
    "OBSNORM_MODES = ('none', 'expertdata', 'online')\n",
    "TINY_ARCHITECTURE = '[{\"type\": \"fc\", \"n\": 64}, {\"type\": \"nonlin\", \"func\": \"tanh\"}, {\"type\": \"fc\", \"n\": 64}, {\"type\": \"nonlin\", \"func\": \"tanh\"}]'\n",
    "SIMPLE_ARCHITECTURE = '[{\"type\": \"fc\", \"n\": 100}, {\"type\": \"nonlin\", \"func\": \"tanh\"}, {\"type\": \"fc\", \"n\": 100}, {\"type\": \"nonlin\", \"func\": \"tanh\"}]'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_taskname2outfile(spec, assert_not_exists=False):\n",
    "    '''\n",
    "    Generate dataset filenames for each task. Phase 0 (sampling) writes to these files,\n",
    "    phase 1 (training) reads from them.\n",
    "    '''\n",
    "    taskname2outfile = {}\n",
    "    trajdir = os.path.join(spec['options']['storagedir'], spec['options']['traj_subdir'])\n",
    "    util.mkdir_p(trajdir)\n",
    "    for task in spec['tasks']:\n",
    "        assert task['name'] not in taskname2outfile\n",
    "        fname = os.path.join(trajdir, 'trajs_{}.h5'.format(task['name']))\n",
    "        if assert_not_exists:\n",
    "            assert not os.path.exists(fname), 'Traj destination {} already exists'.format(fname)\n",
    "        taskname2outfile[task['name']] = fname\n",
    "    return taskname2outfile\n",
    "\n",
    "def load_dataset(filename, limit_trajs, data_subsamp_freq):\n",
    "    # Load expert data\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        # Read data as written by vis_mj.py\n",
    "        full_dset_size = f['obs_B_T_Do'].shape[0] # full dataset size\n",
    "        dset_size = min(full_dset_size, limit_trajs) if limit_trajs is not None else full_dset_size\n",
    "\n",
    "        exobs_B_T_Do = f['obs_B_T_Do'][:dset_size,...][...]\n",
    "        exa_B_T_Da = f['a_B_T_Da'][:dset_size,...][...]\n",
    "        exr_B_T = f['r_B_T'][:dset_size,...][...]\n",
    "        exlen_B = f['len_B'][:dset_size,...][...]\n",
    "\n",
    "    print 'Expert dataset size: {} transitions ({} trajectories)'.format(exlen_B.sum(), len(exlen_B))\n",
    "    print 'Expert average return:', exr_B_T.sum(axis=1).mean()\n",
    "\n",
    "    # Stack everything together\n",
    "    start_times_B = np.random.RandomState(0).randint(0, data_subsamp_freq, size=exlen_B.shape[0])\n",
    "    print 'start times'\n",
    "    print start_times_B\n",
    "    exobs_Bstacked_Do = np.concatenate(\n",
    "        [exobs_B_T_Do[i,start_times_B[i]:l:data_subsamp_freq,:] for i, l in enumerate(exlen_B)],\n",
    "        axis=0)\n",
    "    exa_Bstacked_Da = np.concatenate(\n",
    "        [exa_B_T_Da[i,start_times_B[i]:l:data_subsamp_freq,:] for i, l in enumerate(exlen_B)],\n",
    "        axis=0)\n",
    "    ext_Bstacked = np.concatenate(\n",
    "        [np.arange(start_times_B[i], l, step=data_subsamp_freq) for i, l in enumerate(exlen_B)]).astype(float)\n",
    "\n",
    "    assert exobs_Bstacked_Do.shape[0] == exa_Bstacked_Da.shape[0] == ext_Bstacked.shape[0]# == np.ceil(exlen_B.astype(float)/data_subsamp_freq).astype(int).sum() > 0\n",
    "\n",
    "    print 'Subsampled data every {} timestep(s)'.format(data_subsamp_freq)\n",
    "    print 'Final dataset size: {} transitions (average {} per traj)'.format(exobs_Bstacked_Do.shape[0], float(exobs_Bstacked_Do.shape[0])/dset_size)\n",
    "\n",
    "    return exobs_Bstacked_Do, exa_Bstacked_Da, ext_Bstacked\n",
    "\n",
    "\n",
    "def main(cmd):\n",
    "    with open('./pipelines/im_pipeline.yaml', 'r') as f:\n",
    "        spec = yaml.load(f)\n",
    "    \n",
    "    np.set_printoptions(suppress=True, precision=5, linewidth=1000)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--mode', choices=MODES, required=True)\n",
    "    # Expert dataset\n",
    "    parser.add_argument('--data', type=str, required=True)\n",
    "    parser.add_argument('--limit_trajs', type=int, required=True)\n",
    "    parser.add_argument('--data_subsamp_freq', type=int, required=True)\n",
    "    # MDP options\n",
    "    parser.add_argument('--env_name', type=str, required=True)\n",
    "    parser.add_argument('--max_traj_len', type=int, default=None)\n",
    "    # Policy architecture\n",
    "    parser.add_argument('--policy_type', type=str, default='Gibbs')\n",
    "    parser.add_argument('--policy_hidden_spec', type=str, default=SIMPLE_ARCHITECTURE)\n",
    "    parser.add_argument('--tiny_policy', action='store_true')\n",
    "    parser.add_argument('--obsnorm_mode', choices=OBSNORM_MODES, default='expertdata')\n",
    "    # Behavioral cloning optimizer\n",
    "    parser.add_argument('--bclone_lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--bclone_batch_size', type=int, default=128)\n",
    "    # parser.add_argument('--bclone_eval_nsa', type=int, default=128*100)\n",
    "    parser.add_argument('--bclone_eval_ntrajs', type=int, default=20)\n",
    "    parser.add_argument('--bclone_eval_freq', type=int, default=1000)\n",
    "    parser.add_argument('--bclone_train_frac', type=float, default=.7)\n",
    "    # Imitation optimizer\n",
    "    parser.add_argument('--discount', type=float, default=.995)\n",
    "    parser.add_argument('--lam', type=float, default=.97)\n",
    "    parser.add_argument('--max_iter', type=int, default=1000000)\n",
    "    parser.add_argument('--policy_max_kl', type=float, default=.01)\n",
    "    parser.add_argument('--policy_cg_damping', type=float, default=.1)\n",
    "    parser.add_argument('--no_vf', type=int, default=0)\n",
    "    parser.add_argument('--vf_max_kl', type=float, default=.01)\n",
    "    parser.add_argument('--vf_cg_damping', type=float, default=.1)\n",
    "    parser.add_argument('--policy_ent_reg', type=float, default=0.)\n",
    "    parser.add_argument('--reward_type', type=str, default='nn')\n",
    "    # parser.add_argument('--linear_reward_bin_features', type=int, default=0)\n",
    "    parser.add_argument('--reward_max_kl', type=float, default=.01)\n",
    "    parser.add_argument('--reward_lr', type=float, default=.01)\n",
    "    parser.add_argument('--reward_steps', type=int, default=1)\n",
    "    parser.add_argument('--reward_ent_reg_weight', type=float, default=.001)\n",
    "    parser.add_argument('--reward_include_time', type=int, default=0)\n",
    "    parser.add_argument('--sim_batch_size', type=int, default=None)\n",
    "    parser.add_argument('--min_total_sa', type=int, default=50000)\n",
    "    parser.add_argument('--favor_zero_expert_reward', type=int, default=0)\n",
    "    # Saving stuff\n",
    "    parser.add_argument('--print_freq', type=int, default=100)\n",
    "    parser.add_argument('--save_freq', type=int, default=100)\n",
    "    parser.add_argument('--plot_freq', type=int, default=0)\n",
    "    parser.add_argument('--log', type=str, required=False)\n",
    "\n",
    "    args = parser.parse_args(cmd.split())\n",
    "\n",
    "    # Initialize the MDP\n",
    "    if args.tiny_policy:\n",
    "        assert args.policy_hidden_spec == SIMPLE_ARCHITECTURE, 'policy_hidden_spec must remain unspecified if --tiny_policy is set'\n",
    "        args.policy_hidden_spec = TINY_ARCHITECTURE\n",
    "    argstr = json.dumps(vars(args), separators=(',', ':'), indent=2)\n",
    "\n",
    "    mdp = rlgymenv.RLGymMDP(args.env_name)\n",
    "    util.header('MDP observation space, action space sizes: %d, %d\\n' % (mdp.obs_space.dim, mdp.action_space.storage_size))\n",
    "\n",
    "    # Initialize the policy\n",
    "    enable_obsnorm = args.obsnorm_mode != 'none'\n",
    "    if isinstance(mdp.action_space, policyopt.ContinuousSpace):\n",
    "        if args.policy_type == 'Gaussian':\n",
    "            policy_cfg = rl.GaussianPolicyConfig(\n",
    "                hidden_spec=args.policy_hidden_spec,\n",
    "                min_stdev=0.,\n",
    "                init_logstdev=0.,\n",
    "                enable_obsnorm=enable_obsnorm)\n",
    "            policy = rl.GaussianPolicy(policy_cfg, mdp.obs_space, mdp.action_space, 'GaussianPolicy')\n",
    "        elif args.policy_type == 'GaussianMixture':\n",
    "            policy_cfg = rl.MixtureGaussianPolicyConfig(\n",
    "                hidden_spec=args.policy_hidden_spec,\n",
    "                min_stdev=0.,\n",
    "                init_logstdev=0.,\n",
    "                enable_obsnorm=enable_obsnorm)\n",
    "            policy = rl.MixtureGaussianPolicy(policy_cfg, mdp.obs_space, mdp.action_space, 'GaussianMixturePolicy')\n",
    "        elif args.policy_type == 'GaussianSparseMixture':\n",
    "            policy_cfg = rl.SparseMixtureGaussianPolicyConfig(\n",
    "                hidden_spec=args.policy_hidden_spec,\n",
    "                min_stdev=0.,\n",
    "                init_logstdev=0.,\n",
    "                enable_obsnorm=enable_obsnorm)\n",
    "            policy = rl.SparseMixtureGaussianPolicy(policy_cfg, mdp.obs_space, mdp.action_space, 'GaussianSparseMixturePolicy')\n",
    "    else:\n",
    "        if args.policy_type == 'Gibbs':\n",
    "            policy_cfg = rl.GibbsPolicyConfig(\n",
    "                hidden_spec=args.policy_hidden_spec,\n",
    "                enable_obsnorm=enable_obsnorm)\n",
    "            policy = rl.GibbsPolicy(policy_cfg, mdp.obs_space, mdp.action_space, 'GibbsPolicy')\n",
    "        elif args.policy_type == 'Sparse':\n",
    "            policy_cfg = rl.SparsePolicyConfig(\n",
    "                hidden_spec=args.policy_hidden_spec,\n",
    "                enable_obsnorm=enable_obsnorm)\n",
    "            policy = rl.SparsePolicy(policy_cfg, mdp.obs_space, mdp.action_space, 'SparsePolicy')\n",
    "        \n",
    "    util.header('Policy architecture')\n",
    "    for v in policy.get_trainable_variables():\n",
    "        util.header('- %s (%d parameters)' % (v.name, v.get_value().size))\n",
    "    util.header('Total: %d parameters' % (policy.get_num_params(),))\n",
    "\n",
    "    # Load expert data\n",
    "    exobs_Bstacked_Do, exa_Bstacked_Da, ext_Bstacked = load_dataset(\n",
    "        args.data, args.limit_trajs, args.data_subsamp_freq)\n",
    "    assert exobs_Bstacked_Do.shape[1] == mdp.obs_space.storage_size\n",
    "    assert exa_Bstacked_Da.shape[1] == mdp.action_space.storage_size\n",
    "    assert ext_Bstacked.ndim == 1\n",
    "\n",
    "    # Start optimization\n",
    "    max_traj_len = args.max_traj_len if args.max_traj_len is not None else mdp.env_spec.timestep_limit\n",
    "    print 'Max traj len:', max_traj_len\n",
    "\n",
    "    if args.mode == 'bclone':\n",
    "        # For behavioral cloning, only print output when evaluating\n",
    "        args.print_freq = args.bclone_eval_freq\n",
    "        args.save_freq = args.bclone_eval_freq\n",
    "\n",
    "        reward, vf = None, None\n",
    "        opt = imitation.BehavioralCloningOptimizer(\n",
    "            mdp, policy,\n",
    "            lr=args.bclone_lr,\n",
    "            batch_size=args.bclone_batch_size,\n",
    "            obsfeat_fn=lambda o:o,\n",
    "            ex_obs=exobs_Bstacked_Do, ex_a=exa_Bstacked_Da,\n",
    "            eval_sim_cfg=policyopt.SimConfig(\n",
    "                min_num_trajs=args.bclone_eval_ntrajs, min_total_sa=-1,\n",
    "                batch_size=args.sim_batch_size, max_traj_len=max_traj_len),\n",
    "            eval_freq=args.bclone_eval_freq,\n",
    "            train_frac=args.bclone_train_frac)\n",
    "\n",
    "    elif args.mode == 'ga':\n",
    "        if args.reward_type == 'nn':\n",
    "            reward = imitation.TransitionClassifier(\n",
    "                hidden_spec=args.policy_hidden_spec,\n",
    "                obsfeat_space=mdp.obs_space,\n",
    "                action_space=mdp.action_space,\n",
    "                max_kl=args.reward_max_kl,\n",
    "                adam_lr=args.reward_lr,\n",
    "                adam_steps=args.reward_steps,\n",
    "                ent_reg_weight=args.reward_ent_reg_weight,\n",
    "                enable_inputnorm=True,\n",
    "                include_time=bool(args.reward_include_time),\n",
    "                time_scale=1./mdp.env_spec.timestep_limit,\n",
    "                favor_zero_expert_reward=bool(args.favor_zero_expert_reward),\n",
    "                varscope_name='TransitionClassifier')\n",
    "        elif args.reward_type in ['l2ball', 'simplex']:\n",
    "            reward = imitation.LinearReward(\n",
    "                obsfeat_space=mdp.obs_space,\n",
    "                action_space=mdp.action_space,\n",
    "                mode=args.reward_type,\n",
    "                enable_inputnorm=True,\n",
    "                favor_zero_expert_reward=bool(args.favor_zero_expert_reward),\n",
    "                include_time=bool(args.reward_include_time),\n",
    "                time_scale=1./mdp.env_spec.timestep_limit,\n",
    "                exobs_Bex_Do=exobs_Bstacked_Do,\n",
    "                exa_Bex_Da=exa_Bstacked_Da,\n",
    "                ext_Bex=ext_Bstacked)\n",
    "        else:\n",
    "            raise NotImplementedError(args.reward_type)\n",
    "\n",
    "        vf = None if bool(args.no_vf) else rl.ValueFunc(\n",
    "            hidden_spec=args.policy_hidden_spec,\n",
    "            obsfeat_space=mdp.obs_space,\n",
    "            enable_obsnorm=args.obsnorm_mode != 'none',\n",
    "            enable_vnorm=True,\n",
    "            max_kl=args.vf_max_kl,\n",
    "            damping=args.vf_cg_damping,\n",
    "            time_scale=1./mdp.env_spec.timestep_limit,\n",
    "            varscope_name='ValueFunc')\n",
    "\n",
    "        opt = imitation.ImitationOptimizer(\n",
    "            mdp=mdp,\n",
    "            discount=args.discount,\n",
    "            lam=args.lam,\n",
    "            policy=policy,\n",
    "            sim_cfg=policyopt.SimConfig(\n",
    "                min_num_trajs=-1, min_total_sa=args.min_total_sa,\n",
    "                batch_size=args.sim_batch_size, max_traj_len=max_traj_len),\n",
    "            step_func=rl.TRPO(max_kl=args.policy_max_kl, damping=args.policy_cg_damping),\n",
    "            reward_func=reward,\n",
    "            value_func=vf,\n",
    "            policy_obsfeat_fn=lambda obs: obs,\n",
    "            reward_obsfeat_fn=lambda obs: obs,\n",
    "            policy_ent_reg=args.policy_ent_reg,\n",
    "            ex_obs=exobs_Bstacked_Do,\n",
    "            ex_a=exa_Bstacked_Da,\n",
    "            ex_t=ext_Bstacked)\n",
    "\n",
    "    # Set observation normalization\n",
    "    if args.obsnorm_mode == 'expertdata':\n",
    "        policy.update_obsnorm(exobs_Bstacked_Do)\n",
    "        if reward is not None: reward.update_inputnorm(opt.reward_obsfeat_fn(exobs_Bstacked_Do), exa_Bstacked_Da)\n",
    "        if vf is not None: vf.update_obsnorm(opt.policy_obsfeat_fn(exobs_Bstacked_Do))\n",
    "\n",
    "    # Run optimizer\n",
    "    log = nn.TrainingLog(args.log, [('args', argstr)])\n",
    "    for i in xrange(args.max_iter):\n",
    "        iter_info = opt.step()\n",
    "        log.write(iter_info, print_header=i % (20*args.print_freq) == 0, display=i % args.print_freq == 0)\n",
    "        if args.save_freq != 0 and i % args.save_freq == 0 and args.log is not None:\n",
    "            log.write_snapshot(policy, i)\n",
    "\n",
    "        if args.plot_freq != 0 and i % args.plot_freq == 0:\n",
    "            exdata_N_Doa = np.concatenate([exobs_Bstacked_Do, exa_Bstacked_Da], axis=1)\n",
    "            pdata_M_Doa = np.concatenate([opt.last_sampbatch.obs.stacked, opt.last_sampbatch.a.stacked], axis=1)\n",
    "\n",
    "            # Plot reward\n",
    "            import matplotlib.pyplot as plt\n",
    "            _, ax = plt.subplots()\n",
    "            idx1, idx2 = 0,1\n",
    "            range1 = (min(exdata_N_Doa[:,idx1].min(), pdata_M_Doa[:,idx1].min()), max(exdata_N_Doa[:,idx1].max(), pdata_M_Doa[:,idx1].max()))\n",
    "            range2 = (min(exdata_N_Doa[:,idx2].min(), pdata_M_Doa[:,idx2].min()), max(exdata_N_Doa[:,idx2].max(), pdata_M_Doa[:,idx2].max()))\n",
    "            reward.plot(ax, idx1, idx2, range1, range2, n=100)\n",
    "\n",
    "            # Plot expert data\n",
    "            ax.scatter(exdata_N_Doa[:,idx1], exdata_N_Doa[:,idx2], color='blue', s=1, label='expert')\n",
    "\n",
    "            # Plot policy samples\n",
    "            ax.scatter(pdata_M_Doa[:,idx1], pdata_M_Doa[:,idx2], color='red', s=1, label='apprentice')\n",
    "\n",
    "            ax.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m=== Phase 1: training ===\u001b[0m\n",
      "Gym version: 0.9.3\n",
      "\u001b[95mMDP observation space, action space sizes: 11, 3\n",
      "\u001b[0m\n",
      "\u001b[95mLoading feedforward net specification\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"type\": \"fc\",\n",
      "    \"n\": 100\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"nonlin\",\n",
      "    \"func\": \"tanh\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"fc\",\n",
      "    \"n\": 100\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"nonlin\",\n",
      "    \"func\": \"tanh\"\n",
      "  }\n",
      "]\n",
      "\u001b[95mAffine(in=11, out=100)\u001b[0m\n",
      "\u001b[95mNonlinearity(func=tanh)\u001b[0m\n",
      "\u001b[95mAffine(in=100, out=100)\u001b[0m\n",
      "\u001b[95mNonlinearity(func=tanh)\u001b[0m\n",
      "\u001b[95mAffine(in=100, out=4)\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough dimensions on Elemwise{mul,no_inplace}.0 to reduce on axis 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-72e257e94418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                 }\n\u001b[1;32m     39\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_global_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_templates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-158a9d803f58>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cmd)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0minit_logstdev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 enable_obsnorm=enable_obsnorm)\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixtureGaussianPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GaussianMixturePolicy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GaussianSparseMixture'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             policy_cfg = rl.SparseMixtureGaussianPolicyConfig(\n",
      "\u001b[0;32m/home/kj/Projects/github_sources/sparse_imitation/policyopt/rl.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, obsfeat_space, action_space, varscope_name, n_mixture)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mnum_actiondist_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_mixture\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0menable_obsnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_obsnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             varscope_name=varscope_name)\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_actiondist_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobsfeat_B_Df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kj/Projects/github_sources/sparse_imitation/policyopt/rl.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obsfeat_space, action_space, num_actiondist_params, enable_obsnorm, varscope_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mobjgrad_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# KL divergence from old policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mkl_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_actiondist_kl_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_actiondist_B_Pa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactiondist_B_Pa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mcompute_obj_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobsfeat_B_Df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_actions_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_actiondist_B_Pa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kj/Projects/github_sources/sparse_imitation/policyopt/rl.pyc\u001b[0m in \u001b[0;36m_make_actiondist_kl_ops\u001b[0;34m(self, proposal_actiondist_B_Pa, actiondist_B_Pa)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mproposal_means_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_stdevs_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_mixture_B_Da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_actiondist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_actiondist_B_Pa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mmeans_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdevs_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixture_B_Da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_actiondist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactiondist_B_Pa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mthutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture_gaussian_kl_upbnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_means_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_stdevs_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_mixture_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdevs_B_Da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixture_B_Da\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample_from_actiondist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactiondist_B_Pa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kj/Projects/github_sources/sparse_imitation/policyopt/thutil.py\u001b[0m in \u001b[0;36mmixture_gaussian_kl_upbnd\u001b[0;34m(means1_N_D, stdevs1_N_D, mixture1_N_D, means2_N_D, stdevs2_N_D, mixture2_N_D)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture2_N_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mbest_mixture_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture2_N_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbest_gaussian_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture1_N_D\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgaussian_kl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans1_N_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdevs1_N_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans2_N_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdevs2_N_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_gaussian_kl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/basic.pyc\u001b[0m in \u001b[0;36msum\u001b[0;34m(input, axis, dtype, keepdims, acc_dtype)\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \"\"\"\n\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3067\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melemwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \"\"\"\n\u001b[1;32m    614\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCAReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1345\u001b[0m                     raise ValueError((\n\u001b[1;32m   1346\u001b[0m                         \u001b[0;34m'Not enough dimensions on %s to reduce on axis %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                         % (input, axis)))\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough dimensions on Elemwise{mul,no_inplace}.0 to reduce on axis 2"
     ]
    }
   ],
   "source": [
    "# with open('./pipelines/im_classic_pipeline_sparse.yaml', 'r') as f:\n",
    "# with open('./pipelines/im_classic_pipeline_kj.yaml','r') as f:\n",
    "# with open('./pipelines/im_test_pipeline.yaml','r') as f:\n",
    "with open('./pipelines/im_test_gail_pipeline.yaml','r') as f:\n",
    "    spec = yaml.load(f)\n",
    "\n",
    "util.header('=== Phase 1: training ===')\n",
    "\n",
    "# Generate array job that trains all algorithms\n",
    "# over all tasks, for all dataset sizes (3 loops)\n",
    "\n",
    "taskname2dset = gen_taskname2outfile(spec)\n",
    "\n",
    "# Make checkpoint dir. All outputs go here\n",
    "checkptdir = os.path.join(spec['options']['storagedir'], spec['options']['checkpt_subdir'])\n",
    "util.mkdir_p(checkptdir)\n",
    "# Make sure checkpoint dir is empty\n",
    "# assert not os.listdir(checkptdir), 'Checkpoint directory {} is not empty!'.format(checkptdir)\n",
    "\n",
    "# Assemble the commands to run on the cluster\n",
    "cmd_templates, outputfilenames, argdicts = [], [], []\n",
    "for alg in spec['training']['algorithms']:\n",
    "    for task in spec['tasks']:\n",
    "        for num_trajs in spec['training']['dataset_num_trajs']:\n",
    "            assert num_trajs <= spec['training']['full_dataset_num_trajs']\n",
    "            for run in range(spec['training']['runs']):\n",
    "                # A string identifier. Used in filenames for this run\n",
    "                strid = 'alg={},task={},num_trajs={},run={}'.format(alg['name'], task['name'], num_trajs, run)\n",
    "                cmd_templates = alg['cmd'].replace('\\n', ' ').strip()\n",
    "                outputfilenames = strid + '.txt'\n",
    "                argdicts = {\n",
    "                    'env': task['env'],\n",
    "                    'dataset': taskname2dset[task['name']],\n",
    "                    'num_trajs': num_trajs,\n",
    "                    'cuts_off_on_success': int(task['cuts_off_on_success']),\n",
    "                    'data_subsamp_freq': task['data_subsamp_freq'],\n",
    "                    'out': os.path.join(checkptdir, strid + '.h5'),\n",
    "                }\n",
    "                nn.reset_global_scope()\n",
    "                main(cmd_templates.format(**argdicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
